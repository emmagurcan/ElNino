{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "dir0 = Path('el_nino/')\n",
    "file_sst = 'sst.mnmean.nc'\n",
    "file_2 = 'mslp_coarse.nc'\n",
    "\n",
    "# load the data set with xarray\n",
    "ds_nino = xr.open_dataset(Path(dir0, file_sst))\n",
    "ds_mslp = xr.open_dataset(Path(dir0, file_2))\n",
    "\n",
    "# define 3.4 region\n",
    "lat_min, lat_max = -5.5, 5.5\n",
    "lon_min, lon_max = 190, 240\n",
    "\n",
    "# Interpolating to get rid of the nan-values\n",
    "ds_nino = ds_nino.interpolate_na(dim='lon')\n",
    "ds_mslp = ds_mslp.interpolate_na(dim='lon')\n",
    "\n",
    "# Select the region\n",
    "ds_region_nino = ds_nino.where((ds_nino.lat >= lat_min) & (ds_nino.lat <= lat_max) & \n",
    "                               (ds_nino.lon >= lon_min) & (ds_nino.lon <= lon_max), drop=True)\n",
    "ds_region_mslp = ds_mslp.where((ds_mslp.latitude >= lat_min) & (ds_mslp.latitude <= lat_max) & \n",
    "                               (ds_mslp.longitude >= lon_min) & (ds_mslp.longitude <= lon_max), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting  9 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  10 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  11 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  12 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  13 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  14 months in advance:\n",
      "Cross-validation scores: [1.         0.98947368 1.         1.         1.        ]\n",
      "Average cross-validation score: 0.9978947368421054\n",
      "---------------------------------\n",
      "predicting  15 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  16 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  17 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  18 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  19 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  20 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  21 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  22 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  23 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "predicting  24 months in advance:\n",
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation score: 1.0\n",
      "---------------------------------\n",
      "[[ 0 -1 -1  0  0  0  0  0  0  0  0 -1]\n",
      " [ 0 -1  0  0  0  0  0  0  0  0  0  0]\n",
      " [-1 -1  0  0  0  0  0  0 -1  0  0 -1]\n",
      " [ 0 -1  0  0  0  0  0  0 -1  0  0  0]\n",
      " [-1  1  0  1  1  0  0  0 -1 -1  0  0]\n",
      " [-1 -1  1  0  1  1  0  0 -1 -1  0  0]\n",
      " [-1 -1  0  1  1  1  0 -1 -1  0 -1  0]\n",
      " [ 0 -1  0  1  1 -1  0  0 -1  0 -1  0]\n",
      " [ 0  0  0  0  1  1  0 -1 -1  0  0  0]\n",
      " [ 0  0  0  1  1  1  0 -1 -1 -1 -1  0]\n",
      " [-1  0  0  1  1  1  0 -1 -1 -1 -1 -1]\n",
      " [-1  0  0  1  1  1  0 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  1  1  0  0 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  1  1  1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  0  1  0  0 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  0  1  1  0 -1  0 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the labels from 01/1982 to 05/2021\n",
    "# -2 = Strong La Nina\n",
    "# -1 = La Nina\n",
    "# 0 = Nothing\n",
    "# 1 = El Nino\n",
    "# 2 = Strong El Nino\n",
    "\n",
    "pred_2023 = {}\n",
    "\n",
    "# Initialisation\n",
    "start_date_y = pd.Timestamp(year = 1982, month = 1, day = 1)\n",
    "end_date_y = pd.Timestamp(year = 2021, month = 5, day = 1)\n",
    "current_date = start_date_y\n",
    "\n",
    "# In the end we want to predict what is going to happen in 2023\n",
    "pred_start_date_y = pd.Timestamp(year = 2023, month = 1, day = 1)\n",
    "pred_end_date_y = pd.Timestamp(year = 2023, month = 12, day = 1)\n",
    "\n",
    "# Mean temperature in the region over all the years\n",
    "big_mean = float(ds_region_nino.mean()['sst'])\n",
    "\n",
    "ys = []\n",
    "\n",
    "while current_date <= end_date_y:\n",
    "    # print(current_date)\n",
    "\n",
    "    # Create Timestamps for previous, current, and next months\n",
    "    current_month = current_date\n",
    "    prev_month = current_month - pd.DateOffset(months = 1)\n",
    "    next_month = current_month + pd.DateOffset(months = 1)\n",
    "\n",
    "    # Get data for each month\n",
    "    ds_prev_month = ds_region_nino.sel(time = slice(prev_month, prev_month))\n",
    "    ds_curr_month = ds_region_nino.sel(time = slice(current_month, current_month))\n",
    "    ds_next_month = ds_region_nino.sel(time = slice(next_month, next_month))\n",
    "\n",
    "    # Merge the three datasets\n",
    "    merged_dataset = xr.concat([ds_prev_month, ds_curr_month, ds_next_month], dim='time')\n",
    "\n",
    "    # Calculate the average sea surface temperature along the time dimension\n",
    "    sst_anom = float(merged_dataset['sst'].mean()) - big_mean\n",
    "    # print(current_date, ': ', sst_anom)\n",
    "    cases = [\n",
    "        (sst_anom > 1.5),\n",
    "        (sst_anom >= 0.5) & (sst_anom <= 1.5),\n",
    "        (sst_anom < 0.5) & (sst_anom > -0.5),\n",
    "        (sst_anom <= -0.5) & (sst_anom >= -1.5),\n",
    "        (sst_anom < -1.5),\n",
    "    ]\n",
    "    conditions = [2, 1, 0, -1, -2]\n",
    "    res = np.select(cases, conditions, 0)\n",
    "\n",
    "    ys.append(res)\n",
    "    \n",
    "    # Increment to the first day of the next month\n",
    "    current_date += pd.DateOffset(months = 1)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "ys_np = np.array(ys)\n",
    "\n",
    "# trying to predict El Nino\n",
    "for n_month in range(9,25):\n",
    "    \n",
    "    # Dataset to predict n_month in advance using 1 year of data\n",
    "    start_date_X = start_date_y - pd.DateOffset(years = 1) - pd.DateOffset(months = n_month - 1)\n",
    "    end_date_X = end_date_y - pd.DateOffset(years = 1) - pd.DateOffset(months = n_month - 1)\n",
    "    current_date = start_date_X\n",
    "\n",
    "    # Dataset to make the prediction for 2024\n",
    "    pred_start_date_X = pred_start_date_y - pd.DateOffset(years = 1) - pd.DateOffset(months = n_month - 1)\n",
    "    pred_end_date_X = pred_end_date_y - pd.DateOffset(years = 1) - pd.DateOffset(months = n_month - 1)\n",
    "    current_date_pred = pred_start_date_X\n",
    "\n",
    "    xs_np = {}\n",
    "    xs_np_pred ={}\n",
    "\n",
    "    while current_date <= end_date_X:\n",
    "        \n",
    "        start_variable = current_date\n",
    "        end_variable = current_date + pd.DateOffset(years = 1) - pd.DateOffset(months = 1)\n",
    "        # print(start_variable, ' => ', end_variable)\n",
    "\n",
    "        # Selecting the data for the one-year interval\n",
    "        interval_data = ds_mslp.sel(time=slice(start_variable, end_variable))\n",
    "\n",
    "        # Formatting the interval data\n",
    "        numpy_array = interval_data['msl'].to_numpy()\n",
    "        flattened_data = numpy_array.flatten()\n",
    "        xs_np[str(end_variable.year) + \"/\" + str(end_variable.month + n_month)] = flattened_data\n",
    "        # print(str(end_variable.year) + \"/\" + str(end_variable.month + n_month))\n",
    "\n",
    "        # Increment to the first day of the next month\n",
    "        current_date += pd.DateOffset(months = 1)\n",
    "    \n",
    "    # Extracting the data to predict 2024\n",
    "    while current_date_pred <= pred_end_date_X:\n",
    "    \n",
    "        start_variable = current_date_pred\n",
    "        end_variable = current_date_pred + pd.DateOffset(years = 1) - pd.DateOffset(months = 1)\n",
    "        # print(start_variable, ' => ', end_variable)\n",
    "\n",
    "        # Selecting the data for the one-year interval\n",
    "        interval_data = ds_mslp.sel(time=slice(start_variable, end_variable))\n",
    "\n",
    "        # Formatting the interval data\n",
    "        numpy_array = interval_data['msl'].to_numpy()\n",
    "        flattened_data = numpy_array.flatten()\n",
    "        xs_np_pred[str(end_variable.year) + \"/\" + str(end_variable.month + n_month)] = flattened_data\n",
    "        # print(str(end_variable.year) + \"/\" + str(end_variable.month + n_month))\n",
    "\n",
    "        # Increment to the first day of the next month\n",
    "        current_date_pred += pd.DateOffset(months = 1)\n",
    "\n",
    "    xs_np = np.array(list(xs_np.values()))\n",
    "    xs_np_pred = np.array(list(xs_np_pred.values()))\n",
    "\n",
    "    # Training the Model:\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(xs_np)\n",
    "    X_scaled_pred = scaler.transform(xs_np_pred)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=0.99)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    X_pca_pred = pca.transform(X_scaled_pred)\n",
    "\n",
    "    # Apply LDA\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    X_lda = lda.fit_transform(X_pca, ys_np)\n",
    "    X_lda_pred = lda.transform(X_pca_pred)\n",
    "\n",
    "    # Create the SVM model with a kernel\n",
    "    svm_model = SVC(kernel='rbf')\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(svm_model, X_lda, ys_np, cv = 5)\n",
    "\n",
    "    # After cross-validation, retraining the model on the entire dataset\n",
    "    svm_model.fit(X_lda, ys_np)\n",
    "\n",
    "    # predicting the outcome for 2024\n",
    "    y_pred_2023 = svm_model.predict(X_lda_pred)\n",
    "    pred_2023[str(n_month)] = y_pred_2023\n",
    "\n",
    "    # cv_scores will hold the score for each fold\n",
    "    print ('predicting ', n_month, 'months in advance:')\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Average cross-validation score:\", cv_scores.mean())\n",
    "    print('---------------------------------')\n",
    "\n",
    "pred_2023 = np.array(list(pred_2023.values()))\n",
    "print(pred_2023)\n",
    "\n",
    "# prediction 2023: 0, 0, 0, 0/1, 1, 1, 1, 0, -1, -1, 0/-1, 0/-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  1  1  1  1  1  1  1  2  2  2  2  2  2  1  1  0  0 -1 -1 -1 -1\n",
      " -1 -1  0  0  0  0  0 -1 -1 -1 -2 -2 -2 -1 -1  0  0  0  0 -1 -1 -1 -1 -1\n",
      " -1 -1  0  0  0  0  0  0  0  0  1  1  1  1  1  1  2  2  2  1  1  1  1  1\n",
      "  0  0  0  0  0 -1 -1 -2 -2 -2 -2 -2 -2 -2 -1  0  0  0  0 -1 -1 -1 -1 -1\n",
      "  0  0  0  1  1  1  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  1  1\n",
      "  1  1  2  2  2  1  0  0 -1 -1 -1  0  0  0  1  1  1  1  0  0  0  0  0  0\n",
      "  0  0  0  1  1  1  0  0  0  0  1  1  1  0  1  1  1  0  0 -1 -1 -1 -1 -1\n",
      " -1 -1  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1  0  1  1  2  2  2  2  2  2  2\n",
      "  2  2  2  1  1  0 -1 -1 -1 -2 -2 -2 -2 -1 -1  0  0  0 -1 -1 -1 -2 -2 -2\n",
      " -2 -2 -1  0  0  0  0 -1 -1 -1 -1 -1 -1 -1  0  0  0  0  0  0  0 -1 -1 -1\n",
      " -1  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  1  1  1  0  0  0  0 -1 -1\n",
      " -1 -1  0  0  1  1  0  0  0  0  1  0  0  0  0  0  1  0  0 -1 -1 -2 -2 -2\n",
      " -2 -2 -1  0  0  0  0  0 -1 -1 -1 -1 -1 -1  0  0  1  1  1  1  0  1  1  1\n",
      "  1  1  1  1  1  0 -1 -1 -2 -2 -2 -2 -2 -2 -1  0  0  0  0 -1 -1 -1 -1 -1\n",
      " -1 -1  0  0  1  1  1  0  0  0  0  0 -1 -1  0  0  0  0  0  0 -1  0 -1 -1\n",
      " -1 -1  0  1  1  1  0  0  0  0  0  0  0  0  1  1  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  1  0  0 -1 -1 -1 -1 -1 -1  0  0  1  1  1  0  0 -1 -1 -1 -1\n",
      " -1 -1  0  0  1  1  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0\n",
      "  0  0  1  1  1  0  0 -1 -1 -2 -2 -2 -1 -1  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(ys_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
